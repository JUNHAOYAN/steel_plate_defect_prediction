{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load dataset\n",
    "train_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "test_data = pd.read_csv(\"./dataset/test.csv\")\n",
    "\n",
    "# Check the first few rows of the dataframe\n",
    "# print(train_data.isnull().sum)\n",
    "print(train_data.head(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_columns = [\"Pastry\", \"Z_Scratch\", \"K_Scatch\", \"Stains\", \"Dirtiness\", \"Bumps\", \"Other_Faults\"]\n",
    "feature_columns = [i for i in train_data.columns.tolist()[1:] if i not in target_columns]\n",
    "train_Y = train_data.loc[:, target_columns]\n",
    "train_X = train_data.loc[:, feature_columns]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "train_X_scaler  = scaler.transform(train_X)\n",
    "test_X_scaler = scaler.transform(test_data.drop(\"id\", axis=\"columns\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Grid search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X_scaler, train_Y.to_numpy(), test_size=0.3, random_state=10)\n",
    "\n",
    "# Define the model\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [1500, 2000, 2500],\n",
    "    'learning_rate': [0.003, 0.006, 0.009],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.4, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.35, 0.40, 0.45]\n",
    "}\n",
    "\n",
    "# Configure Grid Search\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Execute Grid Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best score achieved: {grid_search.best_score_}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model building"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.k_fold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "    def fit(self, kwargs):\n",
    "        for fold, (train_idx, test_idx) in enumerate(self.k_fold.split(self.x)):\n",
    "            train_data, train_label = self.x[train_idx], self.y[train_idx]\n",
    "            val_data, val_label = self.x[test_idx], self.y[test_idx]\n",
    "\n",
    "            model = XGBClassifier(**kwargs)\n",
    "            model.fit(train_data, train_label)\n",
    "\n",
    "            train_roc = roc_auc_score(y_true=train_label,y_score=model.predict_proba(train_data))\n",
    "            val_roc = roc_auc_score(y_true=val_label,y_score=model.predict_proba(val_data))\n",
    "            print(\"Fold:\",fold, \" Train ROC:\", np.round(train_roc,5), \" Val ROC:\",np.round(val_roc,5))\n",
    "\n",
    "params = {\"booster\": \"gbtree\",\"verbosity\": 0,\"max_depth\": 5,\"subsample\": 0.7,\"reg_alpha\": 0.54,\n",
    "          \"random_state\": 18,\"n_estimators\": 2000,\"gamma\": 0.44,\"min_child_weight\": 4,\n",
    "          \"reg_lambda\": 0.00001,\"learning_rate\": 0.006,\"colsample_bytree\": 0.38}\n",
    "classifier = Model(train_X_scaler, train_Y.to_numpy())\n",
    "classifier.fit(params)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
